# Chapter 1: Reliable, Scalable, and Maintainable Applications

## Introduction: What Makes a Good Application?

Imagine you're building the next big social media app. Your app goes viral overnight - suddenly you have 10 million users! What happens?

- Does your app **crash** when traffic spikes? ğŸ’¥
- Does it **slow down** to a crawl? ğŸŒ
- Can you **add features** quickly as users demand them? ğŸš€
- Can you **fix bugs** without breaking everything? ğŸ”§

These questions lead to three fundamental concerns in software engineering:

1. **Reliability** - Working correctly even when things go wrong
2. **Scalability** - Handling growth gracefully  
3. **Maintainability** - Making life easier for engineers

This chapter explores what these properties mean and how to achieve them.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  THREE PILLARS OF GOOD APPLICATIONS            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚  RELIABILITY:  Does it work when things fail?  â”‚
â”‚  â””â”€â†’ Hardware crashes, bugs, human errors      â”‚
â”‚                                                â”‚
â”‚  SCALABILITY:  Can it handle growth?           â”‚
â”‚  â””â”€â†’ More users, more data, more complexity    â”‚
â”‚                                                â”‚
â”‚  MAINTAINABILITY:  Can you change it easily?   â”‚
â”‚  â””â”€â†’ Fix bugs, add features, understand code   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Part 1: Thinking About Data Systems

### Modern Applications Are Composite Systems

Gone are the days of "just use a database." Modern apps combine **multiple specialized tools**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TYPICAL MODERN APPLICATION                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚         [Client/Browser]                       â”‚
â”‚                â†“                               â”‚
â”‚         [API Server]                           â”‚
â”‚                â†“                               â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚     â†“          â†“          â†“                    â”‚
â”‚  [Cache]  [Database]  [Search]                 â”‚
â”‚  Redis    PostgreSQL  Elasticsearch            â”‚
â”‚                                                â”‚
â”‚     â†“          â†“          â†“                    â”‚
â”‚  [Message Queue] [Batch Jobs]                  â”‚
â”‚  RabbitMQ        Spark                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Example - E-commerce Application**:

```python
class ProductService:
    def __init__(self):
        self.db = PostgreSQL()         # Primary data storage
        self.cache = Redis()            # Fast reads
        self.search = Elasticsearch()   # Full-text search
        self.queue = RabbitMQ()         # Async tasks
    
    def get_product(self, product_id):
        # 1. Try cache first (fast!)
        cached = self.cache.get(f"product:{product_id}")
        if cached:
            return cached
        
        # 2. Read from database
        product = self.db.query(
            "SELECT * FROM products WHERE id = ?", 
            product_id
        )
        
        # 3. Update cache for next time
        self.cache.set(f"product:{product_id}", product, ttl=3600)
        
        return product
    
    def search_products(self, query):
        # Use search engine for full-text search
        results = self.search.query(query)
        return results
    
    def update_product(self, product_id, data):
        # 1. Update database (source of truth)
        self.db.execute(
            "UPDATE products SET ... WHERE id = ?",
            product_id
        )
        
        # 2. Invalidate cache
        self.cache.delete(f"product:{product_id}")
        
        # 3. Update search index (async)
        self.queue.publish("update_search_index", {
            "product_id": product_id,
            "data": data
        })
```

**Why Multiple Tools?**

Each tool is optimized for specific use cases:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TOOL SPECIALIZATIONS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Database   â”‚ Durable storage, transactions   â”‚
â”‚ Cache      â”‚ Fast reads, temporary data      â”‚
â”‚ Search     â”‚ Full-text search, relevance     â”‚
â”‚ Queue      â”‚ Async processing, decoupling    â”‚
â”‚ Analytics  â”‚ Big data, aggregations          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Blurring Boundaries

Traditional categories are blurring:

- **Redis**: Started as cache, now has persistence
- **Kafka**: Message queue that also stores data permanently
- **Elasticsearch**: Search engine that can be primary database
- **PostgreSQL**: Relational database with JSON support (document-like)

**Your job as engineer**: Compose these tools into a cohesive system that provides the guarantees your application needs.

## Part 2: Reliability

**Definition**: System continues working correctly even when **faults** occur.

**Fault** vs **Failure**:
- **Fault**: One component deviating from spec (disk crash, network issue)
- **Failure**: System as a whole stops providing service to user

```
Fault â†’ System handles it â†’ No Failure âœ…
Fault â†’ System doesn't handle â†’ Failure âŒ
```

**Goal**: Build **fault-tolerant** (or **resilient**) systems.

### Types of Faults

#### 1. Hardware Faults

**Reality Check**: Hardware fails constantly!

**Statistics**:
- Hard disk MTTF (Mean Time To Failure): 10-50 years
- In datacenter with 10,000 disks: 1 disk fails per day!
- Memory errors: 1 error per 100 GB-years
- Power outages: Occasional but impactful

**Example - Disk Failure**:

```
Day 1:  [Disk 1] [Disk 2] [Disk 3] [Disk 4] [Disk 5]
        10,000 disks total

Day 2:  [Disk 1] [Disk 2] ğŸ’¥ [Disk 4] [Disk 5]
        Disk 3 failed!

Without redundancy:
  â†’ Data on Disk 3 is LOST âŒ
  â†’ Applications fail âŒ

With redundancy (RAID):
  â†’ Data also on Disk 5 âœ…
  â†’ Replace Disk 3, rebuild from Disk 5 âœ…
  â†’ Applications keep running âœ…
```

**Traditional Solution**: Hardware redundancy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HARDWARE REDUNDANCY                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Single Point of Failure â†’ Redundant          â”‚
â”‚                                                â”‚
â”‚  [Disk] â†’ [RAID Array]                        â”‚
â”‚  [Server] â†’ [Hot spare server]                â”‚
â”‚  [Power supply] â†’ [Dual power supply]         â”‚
â”‚  [Network] â†’ [Redundant network]              â”‚
â”‚  [Datacenter] â†’ [Multiple datacenters]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Modern Approach**: Software fault tolerance

Instead of preventing faults, **tolerate** them!

```python
# Netflix Chaos Monkey
# Randomly kills production servers to test resilience!

class ChaosMonkey:
    def run(self):
        while True:
            # Pick random server
            server = random.choice(production_servers)
            
            # Kill it!
            print(f"Killing {server}...")
            server.terminate()
            
            # Wait before next chaos
            time.sleep(random.randint(60, 300))

# If your system survives Chaos Monkey, it's truly resilient!
```

**Real-World Example - Amazon AWS**:

Amazon designs for hardware failure:
- EC2 instances can die anytime
- EBS volumes can fail
- Availability zones can go offline
- Applications must handle this gracefully

#### 2. Software Errors

**More insidious** than hardware faults because they're **systematic** - affect many nodes simultaneously.

**Examples**:

1. **Runaway Process**
```python
# Bug: Infinite loop consuming all CPU
def process_data(data):
    while True:  # Oops! Missing break condition
        result = transform(data)
        # Forgot to break!

# All servers run this code
# All servers hit 100% CPU
# Entire system slow! ğŸ’¥
```

2. **Cascading Failure**
```
Service A depends on Service B
Service B becomes slow (not dead, just slow)
Service A keeps waiting for B
Service A's thread pool exhausted
Service A stops responding
Services depending on A fail
...CASCADE! ğŸ’¥ğŸ’¥ğŸ’¥
```

3. **Leap Second Bug (Real!)**

```
2012-06-30 23:59:60 (leap second)
Linux kernel bug: CPU usage spiked to 100%
Affected: Reddit, Yelp, LinkedIn, FourSquare

Why? Kernel's time code couldn't handle 61st second!
```

**Solutions**:

```python
# 1. Timeouts
response = call_service(timeout=5)  # Don't wait forever

# 2. Circuit Breakers
class CircuitBreaker:
    def __init__(self, failure_threshold=5):
        self.failures = 0
        self.threshold = failure_threshold
        self.state = "CLOSED"  # Normal
    
    def call(self, func):
        if self.state == "OPEN":
            raise CircuitBreakerOpen("Too many failures")
        
        try:
            result = func()
            self.failures = 0  # Success! Reset
            return result
        except Exception:
            self.failures += 1
            if self.failures >= self.threshold:
                self.state = "OPEN"  # Stop calling!
            raise

# 3. Rate Limiting
@rate_limit(max_requests=100, per_seconds=60)
def api_call():
    ...

# 4. Monitoring & Alerting
if response_time > 1000:  # 1 second
    alert("Service slow!")
```

#### 3. Human Errors

**Leading cause** of outages!

**Statistics**:
- Configuration errors: 40-80% of outages
- Human error causes more downtime than hardware

**Real-World Disasters**:

1. **GitLab Database Deletion (2017)**
```bash
# Engineer trying to delete secondary database
# Accidentally ran on PRIMARY:
rm -rf /var/opt/gitlab/postgresql/data

# Lost 300 GB of data
# 6 hours downtime
# 5,000 projects affected
```

2. **Amazon S3 Outage (2017)**
```bash
# Engineer meant to remove few servers
# Typo in command:
s3-disable-servers --percentage=1  # Meant to remove 1%
# Actually typed:
s3-disable-servers --number=1      # Removed subsystem #1

# Took down large part of S3
# 4 hours outage
# Half the internet affected!
```

**Solutions**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MINIMIZING HUMAN ERRORS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚  1. Design for Least Surprise                  â”‚
â”‚     - Intuitive APIs, good abstractions        â”‚
â”‚     - Make correct thing easy to do            â”‚
â”‚                                                â”‚
â”‚  2. Decouple High-Risk Places                  â”‚
â”‚     - Sandbox environments                     â”‚
â”‚     - Staging â†’ Production pipeline            â”‚
â”‚                                                â”‚
â”‚  3. Test Thoroughly                            â”‚
â”‚     - Unit tests, integration tests            â”‚
â”‚     - Automated testing                        â”‚
â”‚                                                â”‚
â”‚  4. Quick Recovery                             â”‚
â”‚     - Fast rollback                            â”‚
â”‚     - Gradual rollouts (canary deployments)    â”‚
â”‚                                                â”‚
â”‚  5. Detailed Monitoring                        â”‚
â”‚     - Metrics, logs, traces                    â”‚
â”‚     - Detect problems early                    â”‚
â”‚                                                â”‚
â”‚  6. Training                                   â”‚
â”‚     - Practice failure scenarios               â”‚
â”‚     - GameDays, fire drills                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Example - Safe Deployment**:

```python
def deploy_new_version(version):
    # Step 1: Deploy to 1 server (canary)
    print("Deploying to canary...")
    deploy_to_servers([canary_server], version)
    
    # Step 2: Monitor for 10 minutes
    print("Monitoring canary...")
    time.sleep(600)
    
    metrics = get_metrics(canary_server)
    if metrics['error_rate'] > 0.01:  # 1% errors
        print("âŒ Canary failed! Rolling back...")
        rollback(canary_server)
        return False
    
    # Step 3: Gradual rollout
    print("âœ… Canary success! Rolling out...")
    deploy_to_servers(all_servers[:10], version)   # 10%
    time.sleep(300)  # Wait 5 min
    
    deploy_to_servers(all_servers[:50], version)   # 50%
    time.sleep(300)
    
    deploy_to_servers(all_servers, version)        # 100%
    print("âœ… Deployment complete!")
    return True
```

## Part 3: Scalability

**Definition**: System's ability to cope with increased **load**.

### Describing Load

First, quantify your load using **load parameters**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LOAD PARAMETERS (Examples)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Web server:                                   â”‚
â”‚    - Requests per second                       â”‚
â”‚    - Concurrent users                          â”‚
â”‚                                                â”‚
â”‚  Database:                                     â”‚
â”‚    - Reads per second                          â”‚
â”‚    - Writes per second                         â”‚
â”‚    - Read/write ratio                          â”‚
â”‚                                                â”‚
â”‚  Cache:                                        â”‚
â”‚    - Cache hit rate                            â”‚
â”‚    - Cache size                                â”‚
â”‚                                                â”‚
â”‚  Social network:                               â”‚
â”‚    - Active users per minute                   â”‚
â”‚    - Tweets per day                            â”‚
â”‚    - Home timeline requests                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Case Study: Twitter's Scaling Challenge

**The Problem**: Two main operations

1. **Post tweet** (4,600 requests/sec average, 12,000 peak)
2. **Home timeline** (300,000 requests/sec!)

**Approach 1**: Simple query

```sql
-- User requests home timeline
SELECT tweets.*, users.*
FROM tweets
JOIN users ON tweets.sender_id = users.id
JOIN follows ON follows.followee_id = users.id
WHERE follows.follower_id = current_user
ORDER BY tweets.timestamp DESC
LIMIT 100;

-- Problem: Must query millions of rows!
-- 300,000 queries/sec Ã— expensive query = ğŸ’¥
```

**Approach 2**: Pre-compute timelines

```python
# When user posts tweet:
def post_tweet(user_id, tweet_content):
    # 1. Insert tweet
    tweet_id = db.insert("tweets", {
        "user_id": user_id,
        "content": tweet_content,
        "timestamp": now()
    })
    
    # 2. Fan out to all followers' timelines
    followers = db.query(
        "SELECT follower_id FROM follows WHERE followee_id = ?",
        user_id
    )
    
    for follower in followers:
        # Add tweet to each follower's pre-computed timeline
        cache.append(f"timeline:{follower}", tweet_id)

# When user requests timeline:
def get_timeline(user_id):
    # Just read from cache! Super fast! âœ…
    tweet_ids = cache.get(f"timeline:{user_id}")
    return get_tweets(tweet_ids)
```

**The Challenge**: Celebrities!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TWITTER'S CELEBRITY PROBLEM                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Regular user: 100 followers                   â”‚
â”‚    Tweet â†’ Update 100 timelines âœ…             â”‚
â”‚                                                â”‚
â”‚  Celebrity: 30 million followers               â”‚
â”‚    Tweet â†’ Update 30 million timelines âŒ      â”‚
â”‚    Takes seconds! Too slow!                    â”‚
â”‚                                                â”‚
â”‚  Solution: Hybrid approach                     â”‚
â”‚    - Regular users: Pre-compute timelines      â”‚
â”‚    - Celebrities: Merge on read                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Hybrid Solution**:

```python
def get_timeline(user_id):
    # 1. Get pre-computed timeline (most tweets)
    regular_tweets = cache.get(f"timeline:{user_id}")
    
    # 2. Get celebrity tweets separately
    celebrities = get_celebrities_i_follow(user_id)
    celebrity_tweets = db.query(
        "SELECT * FROM tweets WHERE user_id IN (...) AND timestamp > ?",
        celebrities, one_day_ago
    )
    
    # 3. Merge and sort
    all_tweets = merge_sort(regular_tweets, celebrity_tweets)
    return all_tweets[:100]
```

### Describing Performance

Once you know your load, measure performance:

**Key Metrics**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PERFORMANCE METRICS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Throughput:                                   â”‚
â”‚    - Records processed per second              â”‚
â”‚    - Requests handled per second               â”‚
â”‚    - Example: 10,000 req/sec                   â”‚
â”‚                                                â”‚
â”‚  Response Time:                                â”‚
â”‚    - Time from request to response             â”‚
â”‚    - Includes queueing, processing, network    â”‚
â”‚    - Example: 50ms                             â”‚
â”‚                                                â”‚
â”‚  Latency:                                      â”‚
â”‚    - Time request waits to be handled          â”‚
â”‚    - Subtly different from response time       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Percentiles Matter**:

```python
# Response times for 100 requests (ms):
response_times = [
    10, 12, 15, 18, 20, 22, 25, 28, 30, 35,  # Most requests: fast
    40, 45, 50, 55, 60, 65, 70, 75, 80, 85,
    90, 95, 100, 110, 120, 130, 140, 150, 160, 170,
    180, 190, 200, 220, 240, 260, 280, 300, 350, 400,
    ...,
    5000  # One request: very slow (outlier)
]

# Metrics:
mean = 85ms          # Average (misleading!)
median (p50) = 50ms  # Half are faster
p95 = 200ms          # 95% are faster
p99 = 500ms          # 99% are faster
p99.9 = 2000ms       # 99.9% are faster
```

**Why p99 matters**:

```
Amazon study:
  - Customers with p99 experience (slow) buy LESS
  - 100ms delay = 1% sales loss
  - p99 matters because:
    * Affects real users (not just outliers)
    * Often your best customers (make many requests)
```

**Tail Latency Amplification**:

```
Frontend calls 10 backend services:
  Each service: p99 = 100ms

What's frontend p99?
  NOT 100ms!
  
Probability all 10 respond in <100ms:
  0.99^10 = 0.90 = 90%

So:
  10% of requests take >100ms
  Frontend p90 = Backend p99!
  
Lesson: Tail latencies amplify in distributed systems!
```

### Approaches to Scaling

**Vertical Scaling (Scaling Up)**:
```
Small server:     [2 CPU, 4 GB RAM]  â†’ $50/month
  â†“ Upgrade
Bigger server:    [16 CPU, 64 GB RAM] â†’ $500/month
  â†“ Upgrade  
Huge server:      [96 CPU, 768 GB RAM] â†’ $10,000/month
```

**Pros**:
- âœ… Simple (no code changes)
- âœ… No distributed system complexity

**Cons**:
- âŒ Expensive at high end
- âŒ Single point of failure
- âŒ Limited by hardware (can't scale infinitely)

**Horizontal Scaling (Scaling Out)**:
```
1 server  â†’ [Server 1]
  â†“ Add servers
2 servers â†’ [Server 1] [Server 2]
  â†“ Add more
10 servers â†’ [S1] [S2] [S3] [S4] [S5] [S6] [S7] [S8] [S9] [S10]
```

**Pros**:
- âœ… Cost-effective (use commodity hardware)
- âœ… No single point of failure
- âœ… Can scale almost infinitely

**Cons**:
- âŒ Complex (distributed system challenges)
- âŒ Requires architecting for distribution

**Elastic vs Manual Scaling**:

```python
# Elastic (automatic)
if cpu_usage > 80%:
    add_servers(count=2)
elif cpu_usage < 20%:
    remove_servers(count=1)

# Manual
# Engineer monitors and adds/removes servers
```

**Real-World Example - Netflix**:

- Elastic scaling in AWS
- Handles 300M+ subscribers
- Streams 1 billion hours per week
- Scales up during evening (peak), down at night
- Uses thousands of servers

## Part 4: Maintainability

**Reality**: Software costs:
- 25% initial development
- 75% ongoing maintenance

**Three Design Principles**:

### 1. Operability

Make life easy for operations teams.

**Good Operability Means**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OPERABILITY REQUIREMENTS                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Monitoring: Health, performance visible    â”‚
â”‚  âœ… Automation: Routine tasks automated        â”‚
â”‚  âœ… Documentation: How system works            â”‚
â”‚  âœ… Predictable behavior: No surprises         â”‚
â”‚  âœ… Self-healing: Recover automatically        â”‚
â”‚  âœ… Compatibility: Works with tools            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Example**:

```python
# Good: Comprehensive monitoring
@monitor(
    metrics=['request_count', 'error_rate', 'latency'],
    alerts=[
        {'condition': 'error_rate > 0.01', 'severity': 'high'},
        {'condition': 'latency_p99 > 1000', 'severity': 'medium'}
    ]
)
def process_request(request):
    logger.info(f"Processing request {request.id}")
    try:
        result = do_work(request)
        metrics.increment('success')
        return result
    except Exception as e:
        logger.error(f"Error processing {request.id}: {e}")
        metrics.increment('error')
        raise
```

### 2. Simplicity

Manage complexity through good abstractions.

**Bad - Complex**:
```python
# Spaghetti code
def process_order(order):
    if order.type == 'express':
        if order.region == 'US':
            if order.value > 100:
                # ... 50 lines of logic
            else:
                # ... different logic
        else:
            # ... more branching
    elif order.type == 'standard':
        # ... even more complexity
    # ... 500 lines total ğŸ’€
```

**Good - Simple**:
```python
# Clear abstractions
class OrderProcessor:
    def process(self, order):
        strategy = self.get_strategy(order)
        return strategy.process(order)
    
    def get_strategy(self, order):
        if order.type == 'express':
            return ExpressOrderStrategy()
        else:
            return StandardOrderStrategy()

class ExpressOrderStrategy:
    def process(self, order):
        # Clear, focused logic
        return self.handle_express(order)

class StandardOrderStrategy:
    def process(self, order):
        # Clear, focused logic
        return self.handle_standard(order)
```

### 3. Evolvability (Extensibility)

Make it easy to adapt to change.

**Requirements change!**
- New features needed
- Regulations change
- Business pivots
- Technology evolves

**Design for Change**:

```python
# Bad: Hardcoded
def calculate_price(product):
    price = product.base_price
    price *= 1.1  # Tax (hardcoded!)
    return price

# What if tax changes?
# What if different regions have different tax?
# What if tax rules become complex?

# Good: Extensible
class PriceCalculator:
    def __init__(self, tax_calculator):
        self.tax_calculator = tax_calculator
    
    def calculate(self, product, region):
        base_price = product.base_price
        tax = self.tax_calculator.calculate(base_price, region)
        return base_price + tax

# Easy to change tax rules without changing this code!
tax_calc = USTaxCalculator()  # or EUTaxCalculator(), etc.
calculator = PriceCalculator(tax_calc)
```

## Summary

**Key Takeaways**:

1. **Modern apps are composite systems** combining specialized tools
2. **Reliability** means handling faults gracefully (hardware, software, human)
3. **Scalability** requires understanding load and choosing scaling strategies
4. **Maintainability** comes from operability, simplicity, and evolvability

**Design Principles**:

```
âœ… Design for failure (not if, but when)
âœ… Measure what matters (percentiles, not averages)
âœ… Scale horizontally when possible
âœ… Keep it simple (fight complexity)
âœ… Make it operable (monitoring, automation)
âœ… Design for change (systems evolve)
```

**Next Chapter**: Data Models and Query Languages - how we structure and access data!
