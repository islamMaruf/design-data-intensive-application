# Chapter 5: Replication

## Introduction: Why Replicate Data?

Imagine you run a photo-sharing app like Instagram. You have one server in California storing all photos. What happens if:
- The server crashes? â†’ All photos are lost! ğŸ’¥
- A user in Australia requests a photo? â†’ Takes 2 seconds due to distance ğŸŒ
- 10 million users try to access photos simultaneously? â†’ Server overload! ğŸ”¥

**Solution**: **Replication** - keeping copies of the same data on multiple machines.

**Three Main Reasons to Replicate**:

1. **High Availability**: If one machine fails, others continue serving requests
2. **Reduced Latency**: Serve requests from nearby servers
3. **Increased Throughput**: Distribute load across multiple machines

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           WHY REPLICATE?                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Single Server:                                    â”‚
â”‚  [Database] â†’ ğŸ’¥ Fails = System Down              â”‚
â”‚             â†’ ğŸŒ Far = Slow Response              â”‚
â”‚             â†’ ğŸ”¥ Overload = Can't Handle Load     â”‚
â”‚                                                    â”‚
â”‚  Replicated:                                       â”‚
â”‚  [DB-1] [DB-2] [DB-3]                             â”‚
â”‚    âœ…    âœ…     ğŸ’¥  â†’ Still works (2/3 alive)     â”‚
â”‚    ğŸŒ    ğŸŒ    ğŸŒ   â†’ Serve from nearby copy     â”‚
â”‚    ğŸ“Š    ğŸ“Š    ğŸ“Š   â†’ Split load 3 ways          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The Challenge**: Keeping replicas synchronized is hard! This chapter explores different strategies and their trade-offs.

## Part 1: Leader-Based Replication (Master-Slave)

### How It Works

The most common replication approach uses a **leader** (also called **master** or **primary**) and **followers** (also called **slaves**, **secondaries**, or **read replicas**).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        LEADER-BASED REPLICATION                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚         ğŸ“ WRITES                                   â”‚
â”‚           â”‚                                         â”‚
â”‚           â†“                                         â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚      â”‚ LEADER  â”‚                                    â”‚
â”‚      â”‚ (write) â”‚                                    â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚           â”‚                                         â”‚
â”‚           â”œâ”€â”€â”€â”€ Replication â”€â”€â”€â”€â”                  â”‚
â”‚           â”‚                     â”‚                  â”‚
â”‚           â†“                     â†“                  â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚      â”‚FOLLOWER1â”‚          â”‚FOLLOWER2â”‚             â”‚
â”‚      â”‚ (read)  â”‚          â”‚ (read)  â”‚             â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚           â†‘                     â†‘                  â”‚
â”‚           â”‚                     â”‚                  â”‚
â”‚         ğŸ“– READS             ğŸ“– READS              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Process**:
1. Client sends **write** requests to the leader
2. Leader writes to local storage
3. Leader sends change to all followers (via **replication log**)
4. Followers apply the change
5. Clients can send **read** requests to any replica

**Real-World Example - PostgreSQL Streaming Replication**:

```python
# Application code
import psycopg2

# Write to leader
leader_conn = psycopg2.connect(
    host='db-leader.example.com',
    database='myapp'
)
cursor = leader_conn.cursor()
cursor.execute(
    "INSERT INTO users (name, email) VALUES (%s, %s)",
    ('Alice', 'alice@example.com')
)
leader_conn.commit()

# Read from follower
follower_conn = psycopg2.connect(
    host='db-follower-1.example.com',
    database='myapp'
)
cursor = follower_conn.cursor()
cursor.execute("SELECT * FROM users WHERE email = %s", ('alice@example.com',))
user = cursor.fetchone()
```

**Popular Implementations**:
- **Relational**: PostgreSQL, MySQL, Oracle, SQL Server
- **NoSQL**: MongoDB, RethinkDB, Espresso
- **Distributed**: Kafka (maintains replicated logs)

### Synchronous vs Asynchronous Replication

This is one of the most critical decisions in replication!

#### Synchronous Replication

Leader waits for follower to confirm the write before reporting success.

```
Time: â”€â”€â†’

Client          Leader          Follower 1
  â”‚               â”‚                â”‚
  â”œâ”€ WRITE â”€â”€â†’    â”‚                â”‚
  â”‚               â”œâ”€ Replicate â”€â”€â†’ â”‚
  â”‚               â”‚                â”œâ”€ Write to disk
  â”‚               â”‚    â† ACK â”€â”€â”€â”€â”€â”€â”¤
  â”œ  â† SUCCESS â”€â”€â”€â”¤                â”‚
  â”‚               â”‚                â”‚
```

**Advantages**:
- âœ… **Guaranteed durability**: If leader crashes immediately after acknowledging write, follower has the data
- âœ… **Up-to-date followers**: Followers are always consistent with leader

**Disadvantages**:
- âŒ **Slower writes**: Must wait for network round-trip to follower
- âŒ **Availability risk**: If follower is unavailable or slow, all writes are blocked

**Real-World Impact**: 
- A database in Virginia with synchronous replication to Oregon adds ~60ms latency to EVERY write
- If Oregon datacenter loses network connectivity, ALL writes fail

#### Asynchronous Replication

Leader doesn't wait for followers; sends replication data but continues immediately.

```
Time: â”€â”€â†’

Client          Leader          Follower 1
  â”‚               â”‚                â”‚
  â”œâ”€ WRITE â”€â”€â†’    â”‚                â”‚
  â”‚               â”œâ”€ Replicate â”€â”€â†’ â”‚
  â”œ  â† SUCCESS â”€â”€â”€â”¤                â”‚
  â”‚               â”‚                â”œâ”€ Write to disk
  â”‚               â”‚                â”œâ”€ ACK (ignored)
```

**Advantages**:
- âœ… **Fast writes**: No waiting for followers
- âœ… **High availability**: Leader continues even if all followers are down

**Disadvantages**:
- âŒ **Possible data loss**: If leader crashes before followers receive data, writes are lost
- âŒ **Stale reads**: Followers may be behind, returning outdated data

**Real-World Example - The GitHub Outage (2012)**:

GitHub used MySQL with asynchronous replication. Due to a configuration change:
1. Leader crashed after accepting writes
2. Followers hadn't received the data yet
3. Several minutes of user data (issues, comments, etc.) were lost

This led them to implement semi-synchronous replication (at least one follower must confirm).

#### Semi-Synchronous Replication

A compromise: leader waits for ONE follower, others are asynchronous.

```
Time: â”€â”€â†’

Client    Leader    Follower 1 (sync)   Follower 2 (async)
  â”‚         â”‚             â”‚                    â”‚
  â”œâ”€WRITEâ”€â†’ â”‚             â”‚                    â”‚
  â”‚         â”œâ”€Replicateâ”€â†’ â”‚                    â”‚
  â”‚         â”œâ”€Replicateâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚
  â”‚         â”‚             â”œâ”€ ACK               â”‚
  â”œâ†SUCCESSâ”€â”¤             â”‚                    â”‚
  â”‚         â”‚             â”‚                    â”œâ”€ ACK (ignored)
```

**Best Practice**: This is what most production systems use!
- **MySQL**: semi-sync replication plugin
- **PostgreSQL**: synchronous_standby_names = '1 (follower1, follower2)'

### Setting Up New Followers

**Challenge**: How do you add a new follower to a running system without downtime?

You can't just copy the data files because the leader is constantly being written to!

**Standard Process**:

1. **Take a snapshot** of leader's database (without locking)
2. **Copy snapshot** to new follower
3. **Connect follower** to leader and request all changes since snapshot
4. **Catch up** to leader
5. **Start serving** read requests

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ADDING NEW FOLLOWER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚ Step 1: Snapshot                               â”‚
â”‚  [Leader] â”€â†’ snapshot@position=1000            â”‚
â”‚                                                â”‚
â”‚ Step 2: Copy                                   â”‚
â”‚  snapshot@1000 â”€â”€â”€â”€â”€â”€â”€â”€â†’ [New Follower]       â”‚
â”‚                                                â”‚
â”‚ Step 3: Stream Changes                         â”‚
â”‚  [Leader] â”€â†’ changes from 1000 onward          â”‚
â”‚       â†“                      â†“                 â”‚
â”‚  [Old Follower]        [New Follower]          â”‚
â”‚                                                â”‚
â”‚ Step 4: Caught Up                              â”‚
â”‚  [Leader]@5000                                 â”‚
â”‚  [Old Follower]@5000                           â”‚
â”‚  [New Follower]@5000 â† Ready!                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Real-World Example - MongoDB Replica Set**:

```javascript
// Add new member to replica set
rs.add("mongodb-new.example.com:27017")

// MongoDB automatically:
// 1. Takes snapshot from another member
// 2. Copies data to new member
// 3. Streams oplog (operation log) to catch up
// 4. Marks member as SECONDARY when caught up

// Check status
rs.status()
// Output shows new member catching up:
// { 
//   name: "mongodb-new:27017",
//   state: "RECOVERING",  // Initially
//   ...
// }
// 
// After caught up:
// {
//   name: "mongodb-new:27017", 
//   state: "SECONDARY",  // Ready to serve reads!
//   ...
// }
```

### Handling Node Outages

Systems fail. The question is how to handle it gracefully.

#### Follower Failure: Catch-up Recovery

Relatively easy to handle!

```
Timeline:
T0: [Leader]@position=1000 â†’ [Follower] receives
T1: [Leader]@position=1200 â†’ [Follower] CRASHES ğŸ’¥
T2: [Leader]@position=1400 â†’ (follower down)
T3: [Leader]@position=1600 â†’ (follower down)
T4: [Follower] RESTARTS âœ…
T5: [Follower] checks last position: 1000
T6: [Follower] requests changes from 1000 onwards
T7: [Follower]@position=1600 â†’ Caught up!
```

**Process**:
1. Follower keeps a log of which replication position it last processed
2. After restart, follower requests all changes since that position
3. Once caught up, continues normally

**Implementation**:
```sql
-- PostgreSQL: Check replication status
SELECT client_addr, state, sent_lsn, write_lsn, flush_lsn, replay_lsn
FROM pg_stat_replication;

-- sent_lsn: What leader sent
-- replay_lsn: What follower has applied
-- If follower restarts, it resumes from replay_lsn
```

#### Leader Failure: Failover

Much more complex! This is called **failover**.

**Steps**:
1. **Detect failure**: Usually via timeout (e.g., 30 seconds no heartbeat)
2. **Choose new leader**: Usually the most up-to-date follower
3. **Reconfigure system**: Clients and followers must use new leader
4. **Deal with old leader**: If it comes back, make it a follower

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FAILOVER PROCESS                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚ BEFORE:                                        â”‚
â”‚  [Leader]                                      â”‚
â”‚     â†“                                          â”‚
â”‚  [F1] [F2] [F3]                               â”‚
â”‚                                                â”‚
â”‚ FAILURE:                                       â”‚
â”‚  [Leader] ğŸ’¥                                   â”‚
â”‚     â†“                                          â”‚
â”‚  [F1] [F2] [F3]                               â”‚
â”‚        â†‘                                       â”‚
â”‚    Most up-to-date                             â”‚
â”‚                                                â”‚
â”‚ AFTER FAILOVER:                                â”‚
â”‚  [F2] â† Now leader!                           â”‚
â”‚     â†“                                          â”‚
â”‚  [F1] [F3] [Old Leader (if recovered)]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Challenges**:

1. **Lost Writes with Asynchronous Replication**

```
T0: Client writes X=5 to leader â†’ Leader stores X=5
T1: Leader sends X=5 to followers (async)
T2: Leader crashes ğŸ’¥ (before followers receive)
T3: Follower promoted to new leader (still has X=old_value)
T4: Original leader recovers, has X=5
    New leader has X=old_value
    â†’ Conflict! Which is correct?
```

**Solution**: Usually discard old leader's un-replicated writes. This means **data loss**!

**Real-World Disaster - GitHub (2012)**:
- MySQL leader crashed after accepting writes
- Followers hadn't received some writes
- Promoted follower became new leader
- Lost several minutes of user data (issues, pull requests, comments)
- Required complex recovery process

2. **Split Brain**

Two nodes both think they're the leader!

```
Network Partition:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [Old Leader]   â”‚          â”‚  [New Leader]   â”‚
â”‚  (thinks I'm    â”‚    â•±â•²    â”‚  (thinks I'm    â”‚
â”‚   leader!)      â”‚   â•±  â•²   â”‚   leader!)      â”‚
â”‚       â†“         â”‚  Network â”‚       â†“         â”‚
â”‚  [Client A]     â”‚  Failure â”‚  [Client B]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Both accept writes!
Client A: X = 10
Client B: X = 20

When network heals, which value is correct? ğŸ¤”
```

**Solution**: Use a mechanism to ensure only one leader (e.g., leader leases, consensus algorithms).

3. **Timeout Tuning**

Too short timeout:
- âŒ False positives: Temporary slow network causes unnecessary failover
- âŒ Unnecessary failovers cause load spikes

Too long timeout:
- âŒ Longer recovery time
- âŒ More downtime

**Real-World Example - Netflix**:
Netflix uses automatic failover with 30-second timeout for detecting failures, but requires manual approval for actual failover (to avoid split-brain scenarios).

### Replication Logs Implementation

How does the leader actually send changes to followers? Several approaches:

#### 1. Statement-Based Replication

Send the actual SQL statements.

```sql
-- Leader executes:
INSERT INTO users (id, name) VALUES (1, 'Alice');
UPDATE accounts SET balance = balance + 100 WHERE user_id = 1;

-- Sends these exact statements to followers
-- Followers execute the same SQL
```

**Problems**:

âŒ **Nondeterministic functions**:
```sql
-- Different result on each server!
INSERT INTO logs (timestamp) VALUES (NOW());
INSERT INTO orders (id) VALUES (RAND());
```

âŒ **Auto-incrementing columns**: Different servers might generate different IDs

âŒ **Side effects**: Triggers, stored procedures might behave differently

**Historical Note**: MySQL used statement-based replication before version 5.1. Led to many subtle bugs!

#### 2. Write-Ahead Log (WAL) Shipping

Send the low-level disk write log.

```
Every database uses a WAL for crash recovery:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Write-Ahead Log (PostgreSQL)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Position 1000: Write to page 5, offset 100, bytes: 0xF3A2... â”‚
â”‚ Position 1001: Write to page 5, offset 150, bytes: 0x87BC... â”‚
â”‚ Position 1002: Write to page 8, offset 200, bytes: 0x12DE... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Leader ships this exact log to followers!
```

**Used by**: PostgreSQL, Oracle

**Advantages**:
- âœ… Exact replica: Byte-for-byte identical

**Disadvantages**:
- âŒ **Tightly coupled to storage engine**: Log format contains low-level details
- âŒ **Version incompatibility**: Can't replicate between different database versions

**Real-World Pain Point**: PostgreSQL major version upgrades require dump and restore because WAL format changes!

#### 3. Logical (Row-Based) Log Replication

Send logical representation of changes (which rows changed).

```
Logical Log Format:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transaction 1000:                      â”‚
â”‚   INSERT INTO users                    â”‚
â”‚   Row: (id=123, name='Alice', ...)    â”‚
â”‚                                        â”‚
â”‚ Transaction 1001:                      â”‚
â”‚   UPDATE users WHERE id=123           â”‚
â”‚   Old: (id=123, balance=100)          â”‚
â”‚   New: (id=123, balance=200)          â”‚
â”‚                                        â”‚
â”‚ Transaction 1002:                      â”‚
â”‚   DELETE FROM users WHERE id=456      â”‚
â”‚   Row: (id=456, name='Bob', ...)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Used by**: MySQL binlog (row-based mode), MongoDB oplog

**Advantages**:
- âœ… **Version independent**: Can replicate between different database versions
- âœ… **External applications can parse**: Useful for change data capture (CDC)

**Real-World Use Case - LinkedIn Databus**:

LinkedIn built Databus to stream database changes to other systems:

```
[MySQL] â†’ binlog â†’ [Databus]
                      â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“            â†“            â†“
    [Search]    [Analytics]    [Cache]
```

Users update their profile in MySQL â†’ automatically updates search index, analytics system, and cache!

#### 4. Trigger-Based Replication

Use database triggers to record changes in a custom table.

```sql
-- PostgreSQL example
CREATE TABLE replication_log (
    table_name TEXT,
    operation TEXT,  -- INSERT/UPDATE/DELETE
    row_data JSONB,
    timestamp TIMESTAMP
);

CREATE TRIGGER users_replication
AFTER INSERT OR UPDATE OR DELETE ON users
FOR EACH ROW EXECUTE FUNCTION log_changes();

CREATE FUNCTION log_changes() RETURNS TRIGGER AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        INSERT INTO replication_log VALUES (
            TG_TABLE_NAME, 'INSERT', row_to_json(NEW), NOW()
        );
    ELSIF TG_OP = 'UPDATE' THEN
        INSERT INTO replication_log VALUES (
            TG_TABLE_NAME, 'UPDATE', row_to_json(NEW), NOW()
        );
    ELSIF TG_OP = 'DELETE' THEN
        INSERT INTO replication_log VALUES (
            TG_TABLE_NAME, 'DELETE', row_to_json(OLD), NOW()
        );
    END IF;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;
```

**Advantages**:
- âœ… **Flexible**: Can add custom logic
- âœ… **Selective replication**: Only replicate certain tables/columns

**Disadvantages**:
- âŒ **Performance overhead**: Triggers slow down writes
- âŒ **More complex**: More code to maintain

**Used by**: Oracle GoldenGate, Databus for Oracle

## Part 2: Problems with Replication Lag

Asynchronous replication is fast but creates a window where followers are behind the leader. This is called **replication lag**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         REPLICATION LAG                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Time: 0s                                       â”‚
â”‚  [Leader]@100                                  â”‚
â”‚  [Follower]@100                                â”‚
â”‚  Lag: 0 seconds âœ…                             â”‚
â”‚                                                â”‚
â”‚ Time: 1s (write happens)                       â”‚
â”‚  [Leader]@200                                  â”‚
â”‚  [Follower]@100                                â”‚
â”‚  Lag: 1 second                                 â”‚
â”‚                                                â”‚
â”‚ Time: 5s (heavy load)                          â”‚
â”‚  [Leader]@500                                  â”‚
â”‚  [Follower]@200                                â”‚
â”‚  Lag: 5 seconds âš ï¸                             â”‚
â”‚                                                â”‚
â”‚ Time: Eventually                               â”‚
â”‚  [Leader]@500                                  â”‚
â”‚  [Follower]@500                                â”‚
â”‚  Lag: 0 seconds âœ…                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Usually lag is milliseconds, but can grow to seconds or even minutes under high load. This creates anomalies...

### Problem 1: Reading Your Own Writes

**Scenario**: You update your profile and immediately view it, but see old data!

```
Time: 0s
  Client: [POST /profile] â†’ Leader: name = "Alice"
  Leader: âœ… Saved

Time: 0.5s  
  Leader: name = "Alice"
  Follower-1: name = "Bob" (old value - not replicated yet)

Time: 1s
  Client: [GET /profile] â†’ Follower-1
  Follower-1: Returns name = "Bob" âŒ
  
  User sees old data immediately after update! Confusing!
```

**Real-World Example**:
You post a tweet. You refresh. Your tweet isn't there! You think it failed so you post again. Now you have duplicate tweets!

**Solution: Read-After-Write Consistency**

Ensure users can see their own writes.

**Implementation Strategies**:

1. **Read user's own data from leader**

```python
def get_profile(user_id, requesting_user_id):
    # If viewing your own profile, read from leader
    if user_id == requesting_user_id:
        return read_from_leader(user_id)
    else:
        # Others can read from follower
        return read_from_follower(user_id)
```

2. **Track timestamp of last write**

```python
def write_profile(user_id, data):
    leader.write(user_id, data)
    timestamp = leader.get_replication_timestamp()
    # Return timestamp to client
    return {"success": True, "timestamp": timestamp}

def read_profile(user_id, min_timestamp):
    # Only read from replicas that have caught up
    for follower in followers:
        if follower.replication_timestamp() >= min_timestamp:
            return follower.read(user_id)
    # If no follower caught up, read from leader
    return leader.read(user_id)
```

3. **Read from leader for 1 minute after write**

```python
class UserSession:
    last_write_time = None
    
def read_profile(session, user_id):
    if session.last_write_time and (time.now() - session.last_write_time < 60):
        # Recent write - read from leader
        return leader.read(user_id)
    else:
        return follower.read(user_id)
```

**Real-World: Facebook's Solution**

Facebook uses a hybrid approach:
- Profile updates go to leader
- For ~3 seconds after update, reads come from leader
- After 3 seconds, reads come from nearby cache/follower

### Problem 2: Monotonic Reads

**Scenario**: Time goes backward! You see a comment, refresh, and it disappears!

```
Time: 0s
  [Leader]@100: Comments = ["Good!", "Nice!"]
  [Follower-1]@100: Comments = ["Good!", "Nice!"]
  [Follower-2]@90: Comments = ["Good!"] (lagging)

Time: 1s
  Client: [GET /comments] â†’ Load Balancer â†’ Follower-1
  Sees: ["Good!", "Nice!"]

Time: 2s
  Client: [GET /comments] â†’ Load Balancer â†’ Follower-2
  Sees: ["Good!"] âŒ
  
  "Nice!" disappeared! User thinks comment was deleted!
```

**Real-World Impact**:
Amazon reviews: You see 50 reviews, refresh, see 48 reviews. Confusing!

**Solution: Monotonic Reads**

Once you've seen data at time T, you never see older data.

**Implementation**:

```python
def get_comments(user_id, last_seen_timestamp):
    # Hash user_id to consistently route to same follower
    follower = followers[hash(user_id) % len(followers)]
    
    # Ensure follower has caught up to last_seen_timestamp
    while follower.replication_timestamp() < last_seen_timestamp:
        time.sleep(0.01)  # Wait for replication
    
    data = follower.read()
    new_timestamp = follower.replication_timestamp()
    return data, new_timestamp
```

**Alternative**: Always route same user to same follower (sticky sessions)

```
User Alice (ID: 123) â†’ Always routes to Follower-1
User Bob (ID: 456) â†’ Always routes to Follower-2
```

### Problem 3: Consistent Prefix Reads

**Scenario**: See effects before causes! Like watching a conversation where answers come before questions!

```
Time: 0s
  [Leader]: "What's the capital of France?" 
  [Leader]: "Paris!"

Replication (different speeds):
  [Follower-1]: Receives answer first: "Paris!"
  [Follower-2]: Receives question first: "What's the capital of France?"

User reads:
  Request 1 â†’ Follower-1: Sees "Paris!" (no question) ğŸ¤”
  Request 2 â†’ Follower-2: Sees "What's the capital of France?"
  
  Out of order! Causality violated!
```

**Real-World Example - Social Media**:

```
Alice: "Should I buy the red or blue dress?"
Bob: "Definitely blue!"

Charlie sees (due to replication lag):
Bob: "Definitely blue!" â† Sees this first
Alice: "Should I buy the red or blue dress?" â† Sees this second

Confusing!
```

**Solution: Consistent Prefix Reads**

Causally related writes appear in correct order.

**Implementation for Partitioned Databases**:

```python
# Track causal dependencies
def write_with_causality(data, causal_dependency=None):
    write_id = generate_id()
    
    if causal_dependency:
        # Wait for dependency to be replicated everywhere
        wait_for_replication(causal_dependency)
    
    leader.write(data, write_id, causal_dependency)
    return write_id

# Usage
question_id = write_with_causality("What's the capital of France?")
answer_id = write_with_causality(
    "Paris!", 
    causal_dependency=question_id  # Answer depends on question
)
```

## Part 3: Multi-Leader Replication

### What and Why?

Instead of one leader, have multiple leaders that accept writes.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MULTI-LEADER REPLICATION                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚  Datacenter 1           Datacenter 2           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Leader 1 â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Leader 2 â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â”‚
â”‚       â”‚                     â”‚                  â”‚
â”‚       â†“                     â†“                  â”‚
â”‚  [Followers]            [Followers]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Use Cases

#### 1. Multi-Datacenter Operation

**Single-Leader**:
```
 USA Datacenter              Europe Datacenter
 [Leader]                    [Follower]
    â†‘                             â†‘
    â”‚                             â”‚
 [Users in USA]              [Users in Europe]
    â””â”€â”€ Fast write               â””â”€â”€ SLOW write (must go to USA!)
```

**Multi-Leader**:
```
 USA Datacenter              Europe Datacenter
 [Leader 1] â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  [Leader 2]
    â†‘                             â†‘
    â”‚                             â”‚
 [Users in USA]              [Users in Europe]
    â””â”€â”€ Fast write               â””â”€â”€ Fast write!
```

**Benefits**:
- âœ… Performance: Each region writes to local leader (low latency)
- âœ… Availability: If datacenter connection fails, each can operate independently
- âœ… Network tolerance: No cross-datacenter writes in the critical path

**Real-World Example**: CouchDB's multi-datacenter deployment

#### 2. Clients with Offline Operation

**Example**: Note-taking apps (Evernote, Notion, Google Docs)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OFFLINE-FIRST APPLICATION                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚ Your Phone (offline)                       â”‚
â”‚ [Local Database] â† You edit notes          â”‚
â”‚                                            â”‚
â”‚ Your Laptop (offline)                      â”‚
â”‚ [Local Database] â† You edit notes          â”‚
â”‚                                            â”‚
â”‚ When online:                               â”‚
â”‚ [Phone]  â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                 â†“                          â”‚
â”‚ [Server] â† Synchronize                     â”‚
â”‚                 â†‘                          â”‚
â”‚ [Laptop] â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Each device is effectively a "leader" - accepts writes even when offline!

### The Big Problem: Write Conflicts

**Scenario**: Two users edit the same document simultaneously

```
Time: 0s
  Document: "Distributed Systems are cool"

Time: 1s
  User A (USA): Changes to "Distributed Systems are awesome"
  User B (Europe): Changes to "Distributed Systems are amazing"

  Both writes succeed at their local datacenter!

Time: 2s (replication happens)
  USA datacenter receives: "amazing" from Europe
  Europe datacenter receives: "awesome" from USA
  
  CONFLICT! Which version is correct? ğŸ¤”
```

#### Conflict Avoidance

**Strategy**: Ensure writes for particular record always go to same datacenter.

```python
# Route based on user location
def get_leader_for_user(user_id):
    user = get_user(user_id)
    if user.region == "USA":
        return usa_leader
    elif user.region == "Europe":
        return europe_leader
```

**Works well unless**:
- User travels (USA â†’ Europe)
- Datacenter fails (must reroute to different datacenter)

#### Converging Toward Consistent State

All replicas must eventually have the same data. How?

**1. Last Write Wins (LWW)**

Give each write a timestamp. Highest timestamp wins.

```python
def merge_writes(write_a, write_b):
    if write_a.timestamp > write_b.timestamp:
        return write_a.value
    else:
        return write_b.value

# Example:
write_a = {"value": "awesome", "timestamp": 1000}
write_b = {"value": "amazing", "timestamp": 1001}

result = merge_writes(write_a, write_b)  # "amazing" (higher timestamp)
```

**Problem**: Data loss! "awesome" is discarded even though it was a valid edit.

**Real-World**: Cassandra, Riak use LWW as default

**2. Replica with Higher ID Wins**

Arbitrary but deterministic.

```python
write_a = {"value": "awesome", "replica_id": 1}
write_b = {"value": "amazing", "replica_id": 2}

# Replica 2 > Replica 1, so "amazing" wins
```

**Problem**: Still data loss!

**3. Merge Values**

Concatenate or combine conflicting writes.

```python
write_a = {"value": "awesome"}
write_b = {"value": "amazing"}

# Merge:
result = "awesome/amazing"  # Both preserved!
```

**Problem**: Messy and may not make sense semantically

**4. Store Conflict, Let Application Decide**

Preserve both versions, prompt user to resolve.

```python
def read_document(doc_id):
    versions = database.get_all_versions(doc_id)
    if len(versions) > 1:
        # Return conflict to application
        return {
            "conflict": True,
            "versions": versions
        }
    else:
        return versions[0]
```

**Real-World Example - CouchDB**:

CouchDB returns all conflicting versions:

```json
{
  "_id": "doc123",
  "_conflicts": ["2-abc...", "2-def..."],
  "text": "awesome"  // Current version
}
```

Application must resolve by choosing or merging versions.

**Real-World Example - Google Docs**:

Google Docs uses **Operational Transformation (OT)** to automatically resolve conflicts:

```
User A types: "Hello"
User B types: "World" at same time

OT algorithm transforms operations:
- User A's "Hello" at position 0
- User B's "World" at position 0
  â†’ Transformed to position 5 (after "Hello")

Result: "HelloWorld" âœ… (not "WorldHello")
```

### Multi-Leader Replication Topologies

How do leaders communicate?

#### All-to-All (Most Common)

```
     [Leader 1]
       â†—  â†‘  â†–
      â†™   â”‚   â†˜
[Leader 2]â”€â”¼â”€[Leader 3]
      â†˜   â”‚   â†—
       â†–  â†“  â†™
     [Leader 4]
```

Every leader sends changes to every other leader.

**Advantages**: âœ… Fault-tolerant (many paths)

**Disadvantages**: âŒ Ordering issues (consistent prefix reads problem)

#### Circular

```
[Leader 1] â†’ [Leader 2] â†’ [Leader 3] â†’ [Leader 1]
```

**Advantages**: âœ… Simple

**Disadvantages**: 
- âŒ If one node fails, circle breaks
- âŒ Higher latency (must travel through all nodes)

#### Star

```
        [Leader 1]
         â†™ â†“ â†˜
[Leader 2][Leader 3][Leader 4]
```

Leader 1 is the hub.

**Advantages**: âœ… Simple

**Disadvantages**: âŒ If Leader 1 fails, topology breaks

## Part 4: Leaderless Replication

### What is Leaderless Replication?

No designated leader. Client sends writes to multiple replicas simultaneously.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      LEADERLESS REPLICATION                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚           Client                           â”‚
â”‚             â”‚                              â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚      â†“      â†“      â†“                      â”‚
â”‚  [Node 1][Node 2][Node 3]                 â”‚
â”‚             â†‘                              â”‚
â”‚             â”‚                              â”‚
â”‚      Client reads from                     â”‚
â”‚      multiple nodes                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Used by**: Amazon Dynamo, Cassandra, Riak, Voldemort

### Quorum Reads and Writes

**Key Idea**: Don't require ALL nodes to acknowledge. Use a quorum.

**Parameters**:
- `n` = number of replicas
- `w` = number of nodes that must acknowledge write
- `r` = number of nodes we read from

**Rule**: If `w + r > n`, we're guaranteed to read up-to-date data.

**Example**: n=3, w=2, r=2

```
Write Process:
Client writes X=5
  â†“
Sends to all 3 nodes
  â”œâ†’ Node 1: âœ… ACK
  â”œâ†’ Node 2: âœ… ACK
  â””â†’ Node 3: âŒ Down

Client receives 2 ACKs (w=2) â†’ Write successful!
```

```
Read Process:
Client reads X
  â†“
Sends read to all 3 nodes
  â”œâ†’ Node 1: Returns X=5 (timestamp: 1000)
  â”œâ†’ Node 2: Returns X=5 (timestamp: 1000)
  â””â†’ Node 3: Returns X=3 (timestamp: 900) - stale!

Client got 2 reads (r=2)
Picks latest: X=5 âœ…
```

**Why w+r > n works**:

```
w=2 nodes have latest write
r=2 nodes in read

Since 2+2 > 3, at least one node overlaps!
  
[N1] [N2] [N3]
 âœ…   âœ…   âŒ   â† Write went here (w=2)
 âœ…   âœ…         â† Read from here (r=2)
 
N1 and N2 are in both write and read â†’ guaranteed to see latest!
```

**Common Configurations**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QUORUM CONFIGURATIONS                       â”‚
â”œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  n  â”‚  w  â”‚  r  â”‚     Trade-off            â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3  â”‚  2  â”‚  2  â”‚  Balanced                â”‚
â”‚  3  â”‚  3  â”‚  1  â”‚  Fast reads, slow writes â”‚
â”‚  3  â”‚  1  â”‚  3  â”‚  Fast writes, slow reads â”‚
â”‚  5  â”‚  3  â”‚  3  â”‚  Can tolerate 2 failures â”‚
â”‚  5  â”‚  4  â”‚  2  â”‚  Strong consistency      â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Handling Node Outages

**Scenario**: Node is down during write, comes back later with stale data.

#### Read Repair

When reading, if client detects stale data, update it.

```
Read Process:
Client reads
  â”œâ†’ Node 1: X=5 (timestamp: 1000)
  â”œâ†’ Node 2: X=5 (timestamp: 1000)
  â””â†’ Node 3: X=3 (timestamp: 900) â† Stale!

Client detects Node 3 is stale
  â†’ Sends X=5 to Node 3 to update it

Node 3 now has X=5 âœ…
```

**Limitation**: Only fixes data that is read. Rarely-read data stays stale!

#### Anti-Entropy Process

Background process compares replicas and repairs differences.

```
Background Process (runs periodically):
  Compare Node 1 vs Node 2:
    â†’ If different, sync to latest
  
  Compare Node 1 vs Node 3:
    â†’ If different, sync to latest
    
  Compare Node 2 vs Node 3:
    â†’ If different, sync to latest
```

**Real-World**: Cassandra's "nodetool repair" command

### Detecting Concurrent Writes

**Problem**: Two clients write to same key simultaneously

```
Time: 0s (Both read X=1)
  Client A reads: X=1
  Client B reads: X=1

Time: 1s (Both write)
  Client A writes: X=2
  Client B writes: X=3

Which is correct? ğŸ¤”
```

#### Last Write Wins (LWW)

Attach timestamp, keep latest.

```python
def write(key, value):
    timestamp = time.now()
    for node in nodes:
        node.write(key, value, timestamp)

def read(key):
    values = [node.read(key) for node in nodes]
    # Return value with highest timestamp
    return max(values, key=lambda v: v.timestamp).value
```

**Problem**: Not truly last write in wall-clock time! Clocks can drift.

**Real-World Disaster - Amazon Cart**:

Amazon had a bug where items deleted from cart reappeared due to LWW and clock skew between servers!

#### Version Vectors

Track causal history to detect conflicts.

```python
# Version vector: [NodeID: Version]
# Example:

Time: 0
  Node 1 writes X=A: version = {1:1}
  
Time: 1
  Node 2 reads X=A (version {1:1})
  Node 2 writes X=B: version = {1:1, 2:1}
  
Time: 2 (Concurrent writes)
  Node 1 writes X=C: version = {1:2}
  Node 2 writes X=D: version = {1:1, 2:2}
  
  {1:2} vs {1:1, 2:2} â†’ Not comparable â†’ CONFLICT!
```

**Resolution**: Application decides how to merge.

**Real-World**: Riak uses version vectors to detect conflicts

## Summary

**Key Takeaways**:

1. **Leader-Based Replication**
   - âœ… Simple, widely used
   - âš ï¸ Choose synchronous vs asynchronous carefully
   - âš ï¸ Failover is complex and risky

2. **Replication Lag Problems**
   - Read-after-write consistency
   - Monotonic reads
   - Consistent prefix reads
   - All solvable but require careful design

3. **Multi-Leader Replication**
   - âœ… Better performance, availability
   - âŒ Write conflicts are inevitable
   - Need conflict resolution strategy

4. **Leaderless Replication**
   - âœ… High availability, fault tolerance
   - âš ï¸ Eventual consistency
   - Quorums provide tunable consistency

**Real-World Wisdom**:
- Start with single-leader (simplest)
- Use multi-leader only if you need it (multi-datacenter, offline clients)
- Leaderless for highest availability (Cassandra-style)
- Always measure replication lag in production
- Have monitoring and alerting for failover scenarios

**Next Chapter**: Partitioning - how to split data across multiple machines to scale beyond a single machine's capacity.
